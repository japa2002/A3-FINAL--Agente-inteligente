# Instalar o pacote CatBoost para classificação baseada em gradiente
!pip install catboost

# Importar as bibliotecas necessárias para manipulação de dados, modelagem e visualização
import pandas as pd  # Para manipulação de dataframes
from sklearn.model_selection import train_test_split  # Para dividir os dados em treino e teste
from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier,
                              BaggingClassifier, AdaBoostClassifier, VotingClassifier)  # Modelos de ensemble
from sklearn.tree import DecisionTreeClassifier  # Modelo de Árvore de Decisão
from sklearn.preprocessing import StandardScaler  # Para normalizar os dados
from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix,
                             precision_score, recall_score, f1_score)  # Métricas de avaliação
import seaborn as sns  # Para visualização de dados (gráficos de calor)
import matplotlib.pyplot as plt  # Para criar gráficos
import xgboost as xgb  # Modelo XGBoost
import lightgbm as lgb  # Modelo LightGBM
from catboost import CatBoostClassifier  # Modelo CatBoost

# Carregar o dataset a partir do caminho fornecido
file_path = "/content/drive/MyDrive/A3-dataset/diabetic_data.csv"
df = pd.read_csv(file_path)  # Lê o arquivo CSV em um dataframe

# Exibir as colunas presentes no dataset para validação
print("Colunas do dataset:")
print(df.columns)

# Selecionar apenas as colunas relevantes para a análise
columns_to_use = ['race', 'gender', 'age', 'time_in_hospital', 'num_lab_procedures',
                  'num_medications', 'number_outpatient', 'number_emergency',
                  'number_inpatient', 'diag_1', 'diag_2', 'diag_3', 'A1Cresult',
                  'insulin', 'change', 'diabetesMed', 'readmitted']

# Verificar se as colunas necessárias estão presentes no dataset
missing_columns = [col for col in columns_to_use if col not in df.columns]
if missing_columns:
    print(f"Colunas ausentes no dataset: {missing_columns}")
    raise ValueError("Colunas necessárias estão ausentes no dataset!")  # Gera um erro se faltar alguma coluna
else:
    df = df[columns_to_use]  # Filtra o dataset para usar apenas as colunas selecionadas
    print("Colunas filtradas com sucesso.")

# Pré-processamento dos dados
df.replace('?', None, inplace=True)  # Substitui valores '?' por None (dados ausentes)
df.dropna(inplace=True)  # Remove linhas com valores ausentes

df = pd.get_dummies(df, drop_first=True)  # Realiza a codificação one-hot para variáveis categóricas

# Separar os dados em variáveis independentes (X) e dependente (y)
X = df.drop('readmitted_NO', axis=1)  # Remove a coluna alvo
y = df['readmitted_NO']  # Define a coluna alvo como variável dependente

# Normalizar os dados para padronizar as variáveis
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)  # Aplica a normalização nos dados de entrada

# Dividir os dados em conjuntos de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

# Definir os modelos que serão avaliados
models = {
    'RandomForest': RandomForestClassifier(random_state=42, n_estimators=100, max_depth=5, class_weight='balanced'),
    'GradientBoosting': GradientBoostingClassifier(random_state=42, learning_rate=0.1, n_estimators=100),
    'LightGBM': lgb.LGBMClassifier(random_state=42, learning_rate=0.1, n_estimators=100),
    'XGBoost': xgb.XGBClassifier(random_state=42, learning_rate=0.1, n_estimators=100, use_label_encoder=False, eval_metric='logloss', verbosity=0),
    'CatBoost': CatBoostClassifier(random_state=42, learning_rate=0.1, n_estimators=100, verbose=0),
    'ExtraTrees': ExtraTreesClassifier(random_state=42, n_estimators=100),
    'Bagging': BaggingClassifier(),
    'AdaBoost': AdaBoostClassifier(),
    'DecisionTree': DecisionTreeClassifier(random_state=42, max_depth=5)
}

# Configurar um VotingClassifier que combina vários modelos
voting_model = VotingClassifier(
    estimators=[
        ('RandomForest', models['RandomForest']),
        ('GradientBoosting', models['GradientBoosting']),
        ('LightGBM', models['LightGBM']),
        ('XGBoost', models['XGBoost']),
        ('CatBoost', models['CatBoost'])
    ],
    voting='soft'  # Usa probabilidades dos modelos para combinar predições
)

# Adicionar o modelo de votação ao dicionário de modelos
models['Voting'] = voting_model

# Dicionário para armazenar os resultados das métricas
results = {
    "Modelo": [],
    "Acurácia": [],
    "Precisão": [],
    "Recall": [],
    "F1-Score": []
}

# Treinar e avaliar cada modelo
for model_name, model in models.items():
    print(f"\nTreinando o modelo: {model_name}")
    model.fit(X_train, y_train)  # Treina o modelo nos dados de treino
    y_pred = model.predict(X_test)  # Faz predições nos dados de teste

    # Calcula as métricas de avaliação
    acc = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, zero_division=0)
    recall = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)

    # Adicionar métricas ao dicionário de resultados
    results["Modelo"].append(model_name)
    results["Acurácia"].append(acc)
    results["Precisão"].append(precision)
    results["Recall"].append(recall)
    results["F1-Score"].append(f1)

    # Exibir relatório detalhado e matriz de confusão
    print(f"Acurácia do {model_name}: {acc}")
    print(f"Relatório de Classificação ({model_name}):\n", classification_report(y_test, y_pred, zero_division=0))

    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=["No Readmission", "Readmission"], yticklabels=["No Readmission", "Readmission"])
    plt.title(f"Matriz de Confusão - {model_name}")
    plt.xlabel("Predição")
    plt.ylabel("Real")
    plt.show()

# Comparar os resultados entre os modelos
results_df = pd.DataFrame(results)  # Converte os resultados para um dataframe
print("\nResultados comparativos entre os modelos:")
print(results_df)

# Criar um gráfico comparativo das métricas
plt.figure(figsize=(12, 8))
metrics = ["Acurácia", "Precisão", "Recall", "F1-Score"]
for metric in metrics:
    plt.plot(results["Modelo"], results_df[metric], label=metric, marker='o')

plt.title("Comparação de Desempenho entre Modelos")
plt.xlabel("Modelos")
plt.ylabel("Métricas")
plt.legend()
plt.grid()
plt.show()
